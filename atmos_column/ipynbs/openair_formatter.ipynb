{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import string\n",
    "import statsmodels.api as sm\n",
    "from herbie import Herbie\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import pysolar.solar as solar\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import xarray as xr\n",
    "import pytz\n",
    "import simplekml\n",
    "from pylr2 import regress2\n",
    "import cartopy\n",
    "import sklearn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import funcs.ac_funcs as ac\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions needed for quantile method\n",
    "def get_excess(df,col_list,quantile):\n",
    "    out_df = df.copy()\n",
    "    out_df = subtract_quantile(out_df,col_list,quantile)\n",
    "    return out_df\n",
    "\n",
    "def subtract_quantile(df,col_list,quantile):\n",
    "    for col in col_list:\n",
    "        df[quant_col_label(col,quantile)] = df[col] - get_col_quantile(df,col,quantile)\n",
    "    return df\n",
    "\n",
    "def quant_col_label(col,quantile):\n",
    "    return f'{col}_ex{int(quantile*100)}q'\n",
    "\n",
    "def get_col_quantile(df,col,quantile):\n",
    "    return df[col].quantile(quantile)\n",
    "\n",
    "def rmv_prep(str):\n",
    "    return '_'.join(str.split('_')[1:])\n",
    "\n",
    "def get_ratio(df,idx,min_beforafter,type):\n",
    "    dt1 = idx-datetime.timedelta(minutes=min_beforafter)\n",
    "    dt2 = idx+datetime.timedelta(minutes=min_beforafter)\n",
    "    minidf = df.loc[(df.index>=dt1)&(df.index<=dt2)]\n",
    "    if len(minidf.dropna()) == 0:\n",
    "        return np.nan,np.nan,np.nan\n",
    "    try:\n",
    "        if type=='ch4_co2':\n",
    "            linregress = ac.lin_regress_2(minidf,'xco2(ppm)_ex1q','xch4(ppm)_ex1q')\n",
    "            return linregress['slope'],linregress['r2'],len(minidf.dropna())\n",
    "        elif type == 'ch4_co':\n",
    "            linregress = ac.lin_regress_2(minidf,'xco(ppb)_ex1q','xch4(ppm)_ex1q')\n",
    "            return linregress['slope'],linregress['r2'],len(minidf.dropna())\n",
    "        elif type == 'co_co2':\n",
    "            linregress = ac.lin_regress_2(minidf,'xco2(ppm)_ex1q','xco(ppb)_ex1q')\n",
    "            return linregress['slope'],linregress['r2'],len(minidf.dropna())\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_project_dir = '/uufs/chpc.utah.edu/common/home/u0890904/LAIR_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the side by side data for ua and ha so that we can correct to one another\n",
    "inst_details = {'ha':os.path.join(base_project_dir,'Data/EM27_oof/SLC_EM27_ha_2022_2023_oof_v2_nasrin_correct'),\n",
    "                'ua':os.path.join(base_project_dir,'Data/EM27_oof/summer_2023/elaine_retrievals/ua')}\n",
    "filter_flag_0 = True #set to True if we want to filter bad spectra\n",
    "resample = '5T' #this will resample to that level -- needed to merge dfs and do the regression (and thereby correction)\n",
    "timezone = 'US/Mountain'  #timezone within which to load the dataframes\n",
    "specs = ['xch4(ppm)','xco2(ppm)','xco(ppb)'] #these are the species we want to correct\n",
    "quantile = 0.01\n",
    "min_beforeafter = 30\n",
    "inst_id = 'ha'\n",
    "\n",
    "dt1 = ac.dtstr_to_dttz('2022-05-01 00:00:00',timezone) #get the start and end of the range\n",
    "dt2 = ac.dtstr_to_dttz('2024-01-01 00:00:00',timezone)\n",
    "\n",
    "#Load oof\n",
    "data_folder = inst_details[inst_id] #the data folder is defined in the instrument details dicitonary\n",
    "my_oof_manager = ac.oof_manager(data_folder,timezone) #create the oof manager for that instrument\n",
    "oof_df = my_oof_manager.load_oof_df_inrange(dt1,dt2,filter_flag_0=filter_flag_0,cols_to_load=specs) #load the datetime in the range\n",
    "if resample is not None: #if there is a resample value\n",
    "    oof_df = oof_df.resample(resample).mean(numeric_only = True) #resample to that value by mean\n",
    "daily_dfs = [part for _, part in oof_df.dropna(how='all').groupby(pd.Grouper(freq='1D')) if not part.empty] #parse into a list of daily dataframes\n",
    "oof_with_ex = pd.DataFrame()\n",
    "for i in range(0,len(daily_dfs)):\n",
    "    df = daily_dfs[i][specs]\n",
    "    oof_with_ex = pd.concat([oof_with_ex,get_excess(df,specs,quantile)])\n",
    "if resample is not None: #if there is a resample value\n",
    "    oof_with_ex = oof_with_ex.resample(resample).mean(numeric_only = True) #resample to that value by mean\n",
    "\n",
    "#Add ratios\n",
    "ch4_co2_slope = []\n",
    "ch4_co2_r2 = []\n",
    "ch4_co2_nobs = []\n",
    "ch4_co_slope = []\n",
    "ch4_co_r2 = []\n",
    "ch4_co_nobs = []\n",
    "co_co2_slope = []\n",
    "co_co2_r2 = []\n",
    "co_co2_nobs = []\n",
    "for iloc in range(len(oof_with_ex)):\n",
    "    print(iloc)\n",
    "    idx = oof_with_ex.iloc[iloc].name\n",
    "    ch4_co2 = get_ratio(oof_with_ex,idx,min_beforeafter,'ch4_co2')\n",
    "    ch4_co = get_ratio(oof_with_ex,idx,min_beforeafter,'ch4_co')\n",
    "    co_co2 = get_ratio(oof_with_ex,idx,min_beforeafter,'co_co2')\n",
    "    ch4_co2_slope.append(ch4_co2[0])\n",
    "    ch4_co2_r2.append(ch4_co2[1])\n",
    "    ch4_co2_nobs.append(ch4_co2[2])\n",
    "    ch4_co_slope.append(ch4_co[0])\n",
    "    ch4_co_r2.append(ch4_co[1])\n",
    "    ch4_co_nobs.append(ch4_co[2])\n",
    "    co_co2_slope.append(co_co2[0])\n",
    "    co_co2_r2.append(co_co2[1])\n",
    "    co_co2_nobs.append(co_co2[2])\n",
    "\n",
    "oof_with_ex['ch4_co2_slope'] = ch4_co2_slope\n",
    "oof_with_ex['ch4_co2_r2'] = ch4_co2_r2\n",
    "oof_with_ex['ch4_co2_nobs'] = ch4_co2_nobs\n",
    "oof_with_ex['ch4_co_slope'] = ch4_co_slope\n",
    "oof_with_ex['ch4_co_r2'] = ch4_co_r2\n",
    "oof_with_ex['ch4_co_nobs'] = ch4_co_nobs\n",
    "oof_with_ex['co_co2_slope'] = co_co2_slope\n",
    "oof_with_ex['co_co2_r2'] = ch4_co2_r2\n",
    "oof_with_ex['co_co2_nobs'] = ch4_co2_nobs\n",
    "oof_with_ex = oof_with_ex.dropna(how='all')\n",
    "\n",
    "#Load all of the met data\n",
    "mlg = ac.met_loader_ggg('/uufs/chpc.utah.edu/common/home/u0890904/LAIR_1/Data/met/wbb/daily_txt_gggformat/')\n",
    "wbb_met_df = mlg.load_data_inrange(dt1,dt2)\n",
    "wbb_met_df.index = wbb_met_df.index.tz_convert(timezone)\n",
    "wbb_met_df = wbb_met_df[['pres','temp','rh','u','v']].resample(resample).mean(numeric_only = True)\n",
    "wbb_met_df['ws'],wbb_met_df['wd'] = np.vectorize(ac.uv_to_wdws)(wbb_met_df['u'],wbb_met_df['v'])\n",
    "\n",
    "#Merge met and oof\n",
    "merged_oof_met = pd.concat([wbb_met_df[['ws','wd','u','v']],oof_with_ex],axis = 1)\n",
    "merged_oof_met.index.name = 'dt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'{inst_id}_202205_202311_{resample}_ratios.csv'\n",
    "merged_oof_met.round(5).reset_index().dropna().to_csv(os.path.join(base_project_dir,'Data/csv_for_r/',fname),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 4,cols = 1,shared_xaxes=True)\n",
    "\n",
    "plot_df = merged_oof_met.loc[merged_oof_met.index>'2023-07-01'].dropna()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=plot_df.index,\n",
    "    y = plot_df['xch4(ppm)_ex1q'],\n",
    "    mode = 'markers',\n",
    "    marker_size = 3\n",
    "),row = 1,col = 1)\n",
    "fig.update_yaxes(title_text='xch4(ppm)_ex1q', row=1, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=plot_df.index,\n",
    "    y = plot_df['ch4_co2_slope'],\n",
    "    mode = 'markers',\n",
    "    marker_size = 3\n",
    "),row = 2,col = 1)\n",
    "fig.update_yaxes(title_text='ch4_co2_slope', row=2, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=plot_df.index,\n",
    "    y = plot_df['ws'],\n",
    "    mode = 'markers',\n",
    "    marker_size = 3\n",
    "),row = 3,col = 1)\n",
    "fig.update_yaxes(title_text='ws', row=3, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=plot_df.index,\n",
    "    y = plot_df['wd'],\n",
    "    mode = 'markers',\n",
    "    marker_size = 3\n",
    "),row = 4,col = 1)\n",
    "fig.update_yaxes(title_text='wd', row=4, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height = 700\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmos_column",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
