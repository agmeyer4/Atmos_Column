{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import pytz\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import funcs.ac_funcs as ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oof_manager:\n",
    "    '''Class to manage getting data from oof files'''\n",
    "\n",
    "    def __init__(self,oof_data_folder,timezone):\n",
    "        '''\n",
    "        Args: \n",
    "        oof_data_folder (str) : path to the folder where oof data is stored\n",
    "        timezone (str) : timezone for the measurments\n",
    "        '''\n",
    "        self.oof_data_folder = oof_data_folder\n",
    "        self.timezone = timezone\n",
    "\n",
    "    def load_oof_df_inrange(self,dt1,dt2,filter_flag_0=False,print_out=False,cols_to_load=None):\n",
    "        '''Loads a dataframe from an oof file for datetimes between the input values\n",
    "        \n",
    "        Args:\n",
    "        dt1_str (str) : string for the start time of the desired range of form \"YYYY-mm-dd HH:MM:SS\" \n",
    "        dt2_str (str) : string for the end time of the desired range of form \"YYYY-mm-dd HH:MM:SS\" \n",
    "        oof_filename (str) : name of the oof file to load\n",
    "        filter_flag_0 (bool) : True will filter the dataframe to rows where the flag column is 0 (good data), false returns all the data\n",
    "        print_out (bool) : Will print a message telling the user that they are loading a certain oof file. Default False. \n",
    "        cols_to_load (list) : List of strings that are the names of the oof data columns to load. Default is None, which loads all of the columns. \n",
    "\n",
    "        Returns:\n",
    "        df (pd.DataFrame) : pandas dataframe loaded from the oof files, formatted date, and column names       \n",
    "        '''\n",
    "        if type(dt1) == str:\n",
    "            dt1 = self.tzdt_from_str(dt1)\n",
    "            dt2 = self.tzdt_from_str(dt2)\n",
    "        oof_files_inrange = self.get_oof_in_range(dt1,dt2)\n",
    "        full_df = pd.DataFrame()\n",
    "        for oof_filename in oof_files_inrange:\n",
    "            if print_out:\n",
    "                print(f'Loading {oof_filename}')\n",
    "            df = self.df_from_oof(oof_filename,fullformat = True, filter_flag_0 = filter_flag_0, cols_to_load=cols_to_load) #load the oof file to a dataframe\n",
    "            #df = self.df_dt_formatter(df) #format the dataframe to the correct datetime and column name formats\n",
    "            df = df.loc[(df.index>=dt1)&(df.index<=dt2)] #filter the dataframe between the input datetimes\n",
    "            #if filter_flag_0: #if we want to filter by flag\n",
    "            #    df = df.loc[df['flag'] == 0] #then do it!\n",
    "            full_df = pd.concat([full_df,df])\n",
    "        return full_df\n",
    "\n",
    "    def df_from_oof(self,filename,fullformat = False,filter_flag_0 = False,cols_to_load=None):\n",
    "        '''Load a dataframe from an oof file\n",
    "        \n",
    "        Args:\n",
    "        filename (str) : name of the oof file (not the full path)\n",
    "        fullformat (bool) : if you want to do the full format\n",
    "        filter_flag_0 (bool) : if you want to only get the 0 flags (good data), set to True\n",
    "        cols_to_load (list) : list of strings of the oof columns you want to load. Default None which loads all of the columns\n",
    "        \n",
    "        Returns:\n",
    "        df (pd.DataFrame) : a pandas dataframe loaded from the em27 oof file with applicable columns added/renamed\n",
    "        '''\n",
    "\n",
    "        oof_full_filepath = os.path.join(self.oof_data_folder,filename) #get the full filepath using the class' folder path\n",
    "        header = self.read_oof_header_line(oof_full_filepath)\n",
    "        if cols_to_load == None: #if use_cols is none, we load all of the columns into the dataframe\n",
    "            df = pd.read_csv(oof_full_filepath,\n",
    "                            header = header,\n",
    "                            delim_whitespace=True,\n",
    "                            skip_blank_lines=False) #read it as a csv, parse the header\n",
    "        else:\n",
    "            must_have_cols = ['flag','year','day','hour','lat(deg)','long(deg)','zobs(km)'] #we basically always need these columns\n",
    "            usecols = cols_to_load.copy() #copy the cols to load so it doesn't alter the input list (we often use \"specs\" or simlar)\n",
    "            for mhc in must_have_cols: #loop through the must haves\n",
    "                if mhc not in cols_to_load: #if they aren't in the columns to load\n",
    "                    usecols.append(mhc) #add them \n",
    "\n",
    "            df = pd.read_csv(oof_full_filepath, #now load the dataframe with the specific columns defined\n",
    "                header = header,\n",
    "                delim_whitespace=True,\n",
    "                skip_blank_lines=False,\n",
    "                usecols = usecols) #read it as a csv, parse the header\n",
    "                \n",
    "        df['inst_zasl'] = df['zobs(km)']*1000 #add the instrument z elevation in meters above sea level (instead of km)\n",
    "        df['inst_lat'] = df['lat(deg)'] #rename the inst lat column\n",
    "        df['inst_lon'] = df['long(deg)'] #rename the inst lon column \n",
    "        if fullformat:\n",
    "            df = self.df_dt_formatter(df)\n",
    "        if filter_flag_0:\n",
    "            df = df.loc[df['flag']==0]\n",
    "        return df\n",
    "\n",
    "    def tzdt_from_str(self,dt_str):\n",
    "        '''Apply the inherent timezone of the class to an input datetime string\n",
    "        \n",
    "        Args:\n",
    "        dt_str (str) : datetime string of form \"YYYY-mm-dd HH:MM:SS\" \n",
    "        \n",
    "        Returns:\n",
    "        dt (datetime.datetime) : timezone aware datetime object, with timezone determined by the class\n",
    "        '''\n",
    "\n",
    "        dt = datetime.datetime.strptime(dt_str,'%Y-%m-%d %H:%M:%S') #create the datetime\n",
    "        dt = pytz.timezone(self.timezone).localize(dt) #apply the timezone\n",
    "        return dt\n",
    "\n",
    "    def read_oof_header_line(self,full_file_path):\n",
    "        '''Reads and parses the header line of an oof file\n",
    "        \n",
    "        Args: \n",
    "        full_file_path (str) : full path to an oof file we want to read\n",
    "        \n",
    "        Returns:\n",
    "        header (list) : list of column names to use in the header \n",
    "        '''\n",
    "\n",
    "        with open(full_file_path) as f: #open the file\n",
    "            line1 = f.readline() #read the first line\n",
    "        header = int(line1.split()[0])-1 #plit the file and get the header\n",
    "        return header\n",
    "\n",
    "    def parse_oof_dt(self,year,doy,hr_dec):\n",
    "        '''Get a real datetime from an oof style datetime definition\n",
    "        \n",
    "        Args:\n",
    "        year (int) : year\n",
    "        doy (int) : day of the year \n",
    "        hr_dec (float) : decimal hour of the day\n",
    "        \n",
    "        Returns:\n",
    "        dt (pandas.datetime) : pandas datetime object gleaned from the inputs\n",
    "        '''\n",
    "\n",
    "        dt = pd.to_datetime(f'{int(year)} {int(doy)}',format='%Y %j') + datetime.timedelta(seconds = hr_dec*3600)\n",
    "        return dt\n",
    "\n",
    "    def df_dt_formatter(self,df):\n",
    "        '''Format a loaded oof dataframe to have the correct datetime as an index\n",
    "\n",
    "        Assumes that the oof timestamps are in UTC\n",
    "        \n",
    "        Args: \n",
    "        df (pd.DataFrame) : dataframe loaded using df_from_oof() \n",
    "\n",
    "        Returns:\n",
    "        df (pd.DataFrame) : reformatted dataframe with datetime as the index, and converted to a timezone aware object. \n",
    "        '''\n",
    "\n",
    "        df['dt'] = np.vectorize(self.parse_oof_dt)(df['year'],df['day'],df['hour']) #set the datetime column by parsing the year, day and hour columns\n",
    "        df = df.set_index('dt',drop=True).sort_index() #set dt as the index\n",
    "        df.index = df.index.tz_localize('UTC').tz_convert(self.timezone) #localize and convert the timezone\n",
    "        return df\n",
    "\n",
    "    def get_sorted_oof(self):\n",
    "        '''Get a list of oof files in the oof data folder, sorted so they are in chron order\n",
    "        \n",
    "        Returns:\n",
    "        files (list) : list of files ending in oof in the data folder\n",
    "        '''\n",
    "\n",
    "        files = [] #initialize the list\n",
    "        for file in sorted(os.listdir(self.oof_data_folder)): #loop through the sorted filenames in the oof data folder\n",
    "            if file.endswith('oof'): #if the file ends in oof\n",
    "                files.append(file) #add it to the list\n",
    "        return files\n",
    "\n",
    "    def get_oof_in_range(self,dt1,dt2):\n",
    "        '''Finds the oof files in the data folder that fall between two input datetimes\n",
    "        \n",
    "        Args:\n",
    "        dt1 (str or datetime.datetime) : start datetime of the interval we want to find files within\n",
    "        dt2 (str or datetime.datetime) : end datetime of the interfal we want to find files within\n",
    "        \n",
    "        Returns:\n",
    "        files in range (list) : list of oof filenames that fall within the datetime range input\n",
    "        '''\n",
    "        dt1 = dt1 - datetime.timedelta(days=1) #sometimes with UTC there are values in the previous day's oof file, so start one behind to check\n",
    "        daystrings_in_range = [] #initialize the day strings in the range\n",
    "        delta_days = dt2.date()-dt1.date() #get the number of days delta between the end and the start\n",
    "        for i in range(delta_days.days +1): #loop through that number of days \n",
    "            day = dt1.date() + datetime.timedelta(days=i) #get the day by incrementing by i (how many days past the start)\n",
    "            daystrings_in_range.append(day.strftime('%Y%m%d')) #append a string of the date (YYYYmmdd) to match with filenames\n",
    "\n",
    "        files_in_range = [] #initilize the filenames that will be in the range\n",
    "        for file in self.get_sorted_oof(): #loop through the sorted oof files in the data folder\n",
    "            for daystring_in_range in daystrings_in_range: # loop through the daystrings that are in the range\n",
    "                if daystring_in_range in file: #if the daystring is in the filename, \n",
    "                    files_in_range.append(file) #append it. Otherwise keep going\n",
    "        \n",
    "        return files_in_range\n",
    "\n",
    "    def date_from_oof(self,oof_filename):\n",
    "        '''Strips the date from an oof filename\n",
    "        \n",
    "        Args: \n",
    "        oof_filename (str)\n",
    "\n",
    "        Returns:\n",
    "        date (datetime.datetime.date) : date gained from the oof filename\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            datestring = oof_filename.split('.')[0][2:] #split the oof_filename on . and remove the two letter identifier \n",
    "            date = datetime.datetime.strptime(datestring,\"%Y%m%d\").date() #convert to a date\n",
    "            return date\n",
    "        except:\n",
    "            raise Exception(f'Error in getting datestring from {oof_filename}')\n",
    "\n",
    "    def get_inrange_dates(self,dt1,dt2):\n",
    "        '''Gets a range of dates between an input datetime range\n",
    "        \n",
    "        Args:\n",
    "        dt1 (datetime.datetime) : start datetime\n",
    "        dt2 (datetime.datetime) : end datetime\n",
    "        \n",
    "        Returns:\n",
    "        dates_in_range (list) : list of dates within the datetime range\n",
    "        '''\n",
    "\n",
    "        files_in_range = self.get_oof_in_range(dt1,dt2) #find the files in the range\n",
    "        dates_in_range = [] #initialize the dates list\n",
    "        for oof_filename in files_in_range: #loop through the files in the range\n",
    "            inrange_date = self.date_from_oof(oof_filename) #grab the date\n",
    "            dates_in_range.append(inrange_date) #and append it\n",
    "        return dates_in_range\n",
    "\n",
    "    def check_get_loc(self,oof_df):\n",
    "        '''Checks and gets the location of the instrument from the oof file\n",
    "        TODO: This will break if the location moves during data collection or between days. This could become an issue if data was collected\n",
    "        during one day and went past midnight UTC, then moved to a differnt location the next day. The oof_df in this case for the secnod day\n",
    "        would include some data from the first data colleciton session in the early UTC hours, before moveing. \n",
    "\n",
    "        Args: \n",
    "        oof_df (pd.DataFrame) : dataframe of oof values\n",
    "        \n",
    "        Returns: \n",
    "        inst_lat (float) : instrument latitude\n",
    "        inst_lon (float) : instrument longitude\n",
    "        inst_zasl (float) : instrument elevation above sea level in meters        \n",
    "        '''\n",
    "\n",
    "        cols_to_check = ['inst_lat','inst_lon','inst_zasl']\n",
    "        for col in cols_to_check:\n",
    "            if not pd.col_is_equal(oof_df[col]):\n",
    "                raise Exception('{col} is not the same for the entire oof_df. This is an edge case.')\n",
    "        #If we make it through the above, we can pull the values from the dataframe at the 0th index because they are all the same\n",
    "        inst_lat = oof_df.iloc[0]['inst_lat']\n",
    "        inst_lon = oof_df.iloc[0]['inst_lon']\n",
    "        inst_zasl = oof_df.iloc[0]['inst_zasl']\n",
    "        return inst_lat,inst_lon,inst_zasl   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-07-08 11:03:10.800000-06:00',\n",
       "                      '2023-07-08 11:03:18-06:00',\n",
       "               '2023-07-08 11:03:28.800000-06:00',\n",
       "               '2023-07-08 11:03:32.400000-06:00',\n",
       "               '2023-07-08 11:03:43.200000-06:00',\n",
       "               '2023-07-08 11:03:46.800000-06:00',\n",
       "               '2023-07-08 11:03:57.600000-06:00',\n",
       "               '2023-07-08 11:04:01.200000-06:00',\n",
       "                      '2023-07-08 11:04:12-06:00',\n",
       "               '2023-07-08 11:04:19.200000-06:00',\n",
       "               ...\n",
       "               '2023-07-09 16:18:28.800000-06:00',\n",
       "                      '2023-07-09 16:18:36-06:00',\n",
       "               '2023-07-09 16:18:43.200000-06:00',\n",
       "               '2023-07-09 16:18:50.400000-06:00',\n",
       "               '2023-07-09 16:19:01.200000-06:00',\n",
       "               '2023-07-09 16:19:08.400000-06:00',\n",
       "               '2023-07-09 16:19:15.600000-06:00',\n",
       "               '2023-07-09 16:19:22.800000-06:00',\n",
       "               '2023-07-09 16:19:33.600000-06:00',\n",
       "               '2023-07-09 16:19:37.200000-06:00'],\n",
       "              dtype='datetime64[ns, US/Mountain]', name='dt', length=4484, freq=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the side by side data for ua and ha so that we can correct to one another\n",
    "data_folder = '/uufs/chpc.utah.edu/common/home/u0890904/LAIR_1/Data/EM27_oof/SLC_EM27_ha_2022_2023_oof_v2_nasrin_correct'\n",
    "filter_flag_0 = True #set to True if we want to filter bad spectra\n",
    "timezone = 'UTC'  #timezone within which to load the dataframes\n",
    "specs = ['xch4(ppm)','xco2(ppm)','xco(ppb)'] #these are the species we want to correct\n",
    "\n",
    "#the datetime string ranges below are the ranges when the ua EM27 and ha EM27 were side by side on the roof of wbb\n",
    "dt1_str = '2023-07-08 11:00:00'\n",
    "dt2_str = '2023-07-09 21:59:59'\n",
    "\n",
    "dt1 = datetime.datetime.strptime(dt1_str,'%Y-%m-%d %H:%M:%S') #create the datetime\n",
    "dt1 = pytz.timezone('US/Mountain').localize(dt1) #apply the timezone\n",
    "\n",
    "dt2 = datetime.datetime.strptime(dt2_str,'%Y-%m-%d %H:%M:%S') #create the datetime\n",
    "dt2 = pytz.timezone('US/Mountain').localize(dt2) #apply the timezone\n",
    "\n",
    "my_oof_manager = ac.oof_manager(data_folder,timezone) #create the oof manager for that instrument\n",
    "#my_oof_manager.get_oof_in_range(dt1,dt2)\n",
    "df = my_oof_manager.load_oof_df_inrange(dt1,dt2,filter_flag_0=filter_flag_0,cols_to_load=specs) #load the datetime in the range\n",
    "df.index.tz_convert('US/Mountain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Met data from GGG format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class met_loader_ggg:\n",
    "    def __init__(self,daily_met_path):\n",
    "        self.daily_met_path = daily_met_path\n",
    "\n",
    "    def load_single_file(self,fname):\n",
    "        fullpath = os.path.join(self.daily_met_path,fname)\n",
    "        df = pd.read_csv(fullpath)\n",
    "        return df\n",
    "    \n",
    "    def create_dt_index(self,)\n",
    "    \n",
    "\n",
    "daily_met_path = '/uufs/chpc.utah.edu/common/home/u0890904/WBB_met/daily_csvs'\n",
    "mlg = met_loader_ggg(daily_met_path)\n",
    "\n",
    "df = mlg.read_single_file('20231118_HA.WBB.txt')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_all_wbb_to_df(wbb_data_path,wbb_resample_interval):\n",
    "    wbb_met_df = pd.DataFrame()\n",
    "    for file in os.listdir(wbb_data_path):\n",
    "        fullpath = os.path.join(wbb_data_path,file)\n",
    "        df = pd.read_csv(fullpath,header = 6,skiprows=[7])\n",
    "        df.index = pd.to_datetime(df['Date_Time']).dt.tz_convert(timezone)\n",
    "        df[['u','v']] = df.apply(lambda row: ac.wdws_to_uv(row['wind_speed_set_1'],row['wind_direction_set_1']),axis = 1,result_type='expand')\n",
    "\n",
    "        if wbb_resample_interval == None:\n",
    "            df_resampled = df.copy()\n",
    "        else:\n",
    "            df_resampled = df.resample(wbb_resample_interval).mean(numeric_only=True).dropna(how='all')\n",
    "        df_resampled['ws'],df_resampled['wd'] = np.vectorize(ac.uv_to_wdws)(df_resampled['u'],df_resampled['v'])\n",
    "        wbb_met_df = pd.concat([wbb_met_df,df_resampled])\n",
    "    wbb_met_df = wbb_met_df.sort_index()\n",
    "    wbb_met_df = wbb_met_df.rename(columns={'pressure_set_1':'pressure','air_temp_set_1':'temp'})\n",
    "    wbb_met_df['pressure'] = wbb_met_df['pressure']/100\n",
    "    return wbb_met_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trisonica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_trisonica_to_df(trisonica_data_path,trisonica_resample_interval):\n",
    "    headers_list = ['ET','Date','Time','S','D','U','V','W','T','H','DP','P','AD','PI','RO','MD','TD']\n",
    "    trisonica_df = pd.DataFrame()\n",
    "    for file in os.listdir(trisonica_data_path):\n",
    "        fullpath = os.path.join(trisonica_data_path,file)\n",
    "        with open(fullpath,'r',errors='ignore') as f:\n",
    "            rows_list = []\n",
    "            for i,line in enumerate(f):\n",
    "                newline = line.strip()\n",
    "                if len(newline) < 5:\n",
    "                    continue\n",
    "                newline = newline.replace('=','')\n",
    "                for let in string.ascii_letters.replace('n','').replace('a',''):\n",
    "                    newline = newline.replace(let,'')\n",
    "                newline = newline.replace(',',' ')\n",
    "                if newline[0] == ' ':\n",
    "                    newline = newline[1:]\n",
    "                newline = re.sub(r\"\\s+\",\",\",newline)\n",
    "                line_to_append = newline.split(',')\n",
    "                if len(line_to_append) == len(headers_list):\n",
    "                    rows_list.append(line_to_append)\n",
    "            df = pd.DataFrame(rows_list)\n",
    "            df.columns = headers_list\n",
    "            for col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            df = df.dropna(axis = 1,how = 'all')\n",
    "            df['DT'] = pd.to_datetime(df['ET'],unit='s')\n",
    "            df = df.set_index('DT')\n",
    "            df.index = df.index.tz_localize('UTC').tz_convert(timezone)\n",
    "            df = df.drop(['S','D'],axis = 1)\n",
    "            if trisonica_resample_interval is not None:\n",
    "                df = df.resample(trisonica_resample_interval).mean(numeric_only=True)\n",
    "        trisonica_df = pd.concat([trisonica_df,df])\n",
    "    trisonica_df = trisonica_df.sort_index()\n",
    "    trisonica_df['ws'],trisonica_df['wd'] = np.vectorize(ac.uv_to_wdws)(trisonica_df['U'],trisonica_df['V'])\n",
    "    return trisonica_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmos_column",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
